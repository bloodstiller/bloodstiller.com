<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Function-Calling on Bloodstiller: Ethical Hacking &amp; Active Directory Security Blog</title>
    <link>http://localhost:1313/tags/function-calling/</link>
    <description>Recent content in Function-Calling on Bloodstiller: Ethical Hacking &amp; Active Directory Security Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 12 Oct 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/function-calling/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM APIs Lab 3: Indirect Prompt Injection</title>
      <link>http://localhost:1313/portswigger/llm_apis_lab_3/</link>
      <pubDate>Sun, 12 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/portswigger/llm_apis_lab_3/</guid>
      <description>&lt;h2 id=&#34;lab-3-indirect-prompt-injection&#34;&gt;Lab 3: Indirect Prompt Injection:&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;This lab is vulnerable to indirect prompt injection. The user carlos frequently uses the live chat to ask about the Lightweight &amp;ldquo;l33t&amp;rdquo; Leather Jacket product. To solve the lab, delete carlos.&#xA;Required knowledge&lt;/p&gt;&#xA;&lt;p&gt;To solve this lab, you need to know:&lt;/p&gt;&#xA;&lt;p&gt;How LLM APIs work.&#xA;How to map LLM API attack surface.&#xA;How to execute indirect prompt injection attacks.&lt;/p&gt;&#xA;&lt;p&gt;For more information, see our Web LLM attacks Academy topic.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM APIs Lab 1: Guardrails &amp; Consent Checks for Tool-Calling Models</title>
      <link>http://localhost:1313/portswigger/llm_apis_lab_1/</link>
      <pubDate>Sat, 11 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/portswigger/llm_apis_lab_1/</guid>
      <description>&lt;h2 id=&#34;lab-1-exploiting-llm-apis-with-excessive-agency&#34;&gt;Lab 1: Exploiting LLM APIs with excessive agency:&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;To solve the lab, use the LLM to delete the user carlos.&#xA;Required knowledge&lt;/p&gt;&#xA;&lt;p&gt;To solve this lab, you&amp;rsquo;ll need to know:&lt;/p&gt;&#xA;&lt;p&gt;How LLM APIs work.&#xA;How to map LLM API attack surface.&lt;/p&gt;&#xA;&lt;p&gt;For more information, see our Web LLM attacks Academy topic.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;initial-reconnaissance-discovery&#34;&gt;Initial Reconnaissance/Discovery:&lt;/h3&gt;&#xA;&lt;p&gt;We can see there is a live function chat function on the page:&#xA;&lt;p class=&#34;imgp&#34;&gt;&#xA;  &lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/ox-hugo/2025-10-09-110109.png&#34; alt=&#34;&#34;  /&gt;&#xA;&lt;/p&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;Clicking it allows us to interact with a chat bot using the live chat function:&#xA;&lt;p class=&#34;imgp&#34;&gt;&#xA;  &lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/ox-hugo/2025-10-09-110210.png&#34; alt=&#34;&#34;  /&gt;&#xA;&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM APIs Lab 2: OS Command Injection via Tool-Calling API</title>
      <link>http://localhost:1313/portswigger/llm_apis_lab_2/</link>
      <pubDate>Sat, 11 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/portswigger/llm_apis_lab_2/</guid>
      <description>&lt;h2 id=&#34;lab-2-exploiting-vulnerabilities-in-llm-apis&#34;&gt;Lab 2: Exploiting vulnerabilities in LLM APIs:&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;This lab contains an OS command injection vulnerability that can be exploited via its APIs. You can call these APIs via the LLM. To solve the lab, delete the morale.txt file from Carlos&amp;rsquo; home directory.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;initial-reconnaissance-discovery&#34;&gt;Initial Reconnaissance/Discovery:&lt;/h3&gt;&#xA;&lt;p&gt;Much like lab 1 we are presented a web store which has access to an Email Client we can use as well as a Live Chat function where we can access the LLM.&#xA;&lt;p class=&#34;imgp&#34;&gt;&#xA;  &lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/ox-hugo/2025-10-10_15-23.png&#34; alt=&#34;&#34;  /&gt;&#xA;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
